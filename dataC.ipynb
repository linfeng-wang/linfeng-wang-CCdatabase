{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>C - Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import icecream as ic\n",
    "import numpy as np\n",
    "import plotly\n",
    "import matplotlib as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "import psycopg2.extras\n",
    "import csv\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C1: small-molecule roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acetazolamide\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'has_part': [['Diamox'],\n",
       "  ['Sodium acetazolamide'],\n",
       "  ['sodium [(5-acetamido-1,3,4-thiadiazol-2-yl)sulfonyl]azanide'],\n",
       "  ['N-(5-Sulfamoyl-1,3,4-thiadiazol-2-yl)acetamide monosodium salt']],\n",
       " 'is_conjugate_base_of': [['[(5-acetamido-1,3,4-thiadiazol-2-yl)sulfonyl]azanide'],\n",
       "  ['acetazolamide']]}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chebi database\n",
    "\n",
    "hostname = 'localhost'\n",
    "database = 'Chebi'\n",
    "username = 'postgres'\n",
    "pwd = 'wlf1115'\n",
    "port_id = 5432\n",
    "conn = None\n",
    "\n",
    "query = 'Acetazolamide'\n",
    "with psycopg2.connect(\n",
    "                    host = hostname,\n",
    "                    dbname = database,\n",
    "                    user = username,\n",
    "                    password = pwd,\n",
    "                    port = port_id) as conn:\n",
    "    with conn.cursor(cursor_factory=psycopg2.extras.DictCursor) as cur:\n",
    "\n",
    "        query_script = '''SELECT type, final_id\n",
    "                        FROM relation\n",
    "                        WHERE init_id = (\n",
    "                            SELECT compound_id\n",
    "                            FROM names\n",
    "                            WHERE name IN (%s)\n",
    "                            )'''\n",
    "        cur.execute(query_script, (query,))\n",
    "        \n",
    "        type_id = {}\n",
    "        type_compound = {}\n",
    "        for record in cur.fetchall():\n",
    "            type_id[record[0]] = []\n",
    "            type_compound[record[0]] = []\n",
    "            type_id[record[0]] = record[1]\n",
    "\n",
    "\n",
    "        for k,v in type_id.items():\n",
    "            # query1 = '''SELECT name\n",
    "            #             FROM names\n",
    "            #             WHERE compound_id IN ({}\n",
    "            #             )'''.format(tuple([x]))\n",
    "            query_script1 = '''SELECT name\n",
    "                        FROM names\n",
    "                        WHERE compound_id IN (%s)\n",
    "                        '''\n",
    "            query1 = tuple([v])\n",
    "            cur.execute(query_script1, query1)\n",
    "            for record in cur.fetchall():\n",
    "                type_compound[k].append(record)\n",
    "\n",
    "print(query)\n",
    "type_compound    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C2: metabolic pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.ebi.ac.uk/biomodels/MODEL1109130000#Files #!how to get binary data, how is the graph represented # read paper\n",
    "# We downloaded the reconstruction of human metabolism (Recon)57 from Pathway Commons58 (http://www.pathwaycommons.org, July 2017) in binary interaction form. \n",
    "# Data were represented as an undirected graph where nodes are metabolites and edges denote reactions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>init</th>\n",
       "      <th>process</th>\n",
       "      <th>affected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A4GALT</td>\n",
       "      <td>catalysis-precedes</td>\n",
       "      <td>B3GALNT1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A4GALT</td>\n",
       "      <td>catalysis-precedes</td>\n",
       "      <td>B3GNT3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A4GALT</td>\n",
       "      <td>controls-production-of</td>\n",
       "      <td>CHEBI:58223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A4GALT</td>\n",
       "      <td>catalysis-precedes</td>\n",
       "      <td>ENTPD4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A4GALT</td>\n",
       "      <td>catalysis-precedes</td>\n",
       "      <td>NME1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52598</th>\n",
       "      <td>ZADH2</td>\n",
       "      <td>controls-production-of</td>\n",
       "      <td>CHEBI:17790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52599</th>\n",
       "      <td>ZADH2</td>\n",
       "      <td>controls-production-of</td>\n",
       "      <td>CHEBI:18041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52600</th>\n",
       "      <td>ZADH2</td>\n",
       "      <td>controls-production-of</td>\n",
       "      <td>CHEBI:28972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52601</th>\n",
       "      <td>ZADH2</td>\n",
       "      <td>catalysis-precedes</td>\n",
       "      <td>GLO1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52602</th>\n",
       "      <td>ZADH2</td>\n",
       "      <td>catalysis-precedes</td>\n",
       "      <td>HPRT1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>52603 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         init                 process     affected\n",
       "0      A4GALT      catalysis-precedes     B3GALNT1\n",
       "1      A4GALT      catalysis-precedes       B3GNT3\n",
       "2      A4GALT  controls-production-of  CHEBI:58223\n",
       "3      A4GALT      catalysis-precedes       ENTPD4\n",
       "4      A4GALT      catalysis-precedes         NME1\n",
       "...       ...                     ...          ...\n",
       "52598   ZADH2  controls-production-of  CHEBI:17790\n",
       "52599   ZADH2  controls-production-of  CHEBI:18041\n",
       "52600   ZADH2  controls-production-of  CHEBI:28972\n",
       "52601   ZADH2      catalysis-precedes         GLO1\n",
       "52602   ZADH2      catalysis-precedes        HPRT1\n",
       "\n",
       "[52603 rows x 3 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recon_df = pd.read_csv(\"../PathwayCommons.8.reconx.BINARY_SIF.hgnc.txt\", sep='\\t', names=['init', 'process','affected'])\n",
    "recon_df #how to convert protein name to abbreviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C3: signaling pathways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  C3 space (and the C4 and C5 spaces) is aimed at any molecule with known protein targets. \n",
    "# In this case, we list the biological pathways that may be affected by the interaction of a molecule with its targets. \n",
    "# Human pathways were collected from Reactome (https://reactome.org, May 2017) #! use of graphDB\n",
    "\n",
    "# we chose to use binding activities from B4, since this is an extensive dataset containing mostly literature data with well-accepted activity thresholds. \n",
    "# In B4, 24.5% of the compound–protein interactions do not correspond to human proteins. #!need B4 data\n",
    "# These were mapped to their human orthologs using MetaPhOrs60 (http://orthology.phylomedb.org, May 2017), following the observation that binding activities can be safely transferred between orthologous proteins61,  #!how is it done, it is a database?\n",
    "# especially if they belong to closely related species, as it is the case for B4 data62. Of all the nonhuman proteins mapped to the human orthologs, 94.4% were mammal proteins #!http://orthology.phylomedb.org/download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/78/zn54_c9d2jb_8j8xx5s59dqw0000gn/T/ipykernel_1245/1950680321.py:4: DtypeWarning: Columns (5,7,8,9,10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  chemble_B1 = pd.read_csv(\"../chembl31forlinfeng/B1_data.csv\", sep=',', header=0)\n"
     ]
    }
   ],
   "source": [
    "reactome_df = pd.read_csv(\"../UniProt2Reactome_All_Levels.txt\", sep='\\t', names=['uniprot_id','interaction_code','web','pathway','IEA','organism'])\n",
    "reactome_df = reactome_df[['uniprot_id','pathway']]\n",
    "\n",
    "chemble_B1 = pd.read_csv(\"../chembl31forlinfeng/B1_data.csv\", sep=',', header=0)\n",
    "chemble_B1_target_uniprot = chemble_B1[chemble_B1['compound_name']=='Acetazolamide']['uniprot_id']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniprot_id</th>\n",
       "      <th>pathway</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>412824</th>\n",
       "      <td>O00255</td>\n",
       "      <td>Signal Transduction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412825</th>\n",
       "      <td>O00255</td>\n",
       "      <td>Signaling by TGF-beta Receptor Complex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412826</th>\n",
       "      <td>O00255</td>\n",
       "      <td>Signaling by Rho GTPases</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412827</th>\n",
       "      <td>O00255</td>\n",
       "      <td>RHO GTPase Effectors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412828</th>\n",
       "      <td>O00255</td>\n",
       "      <td>Signaling by WNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903808</th>\n",
       "      <td>Q9Y6L6</td>\n",
       "      <td>Disorders of transmembrane transporters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903809</th>\n",
       "      <td>Q9Y6L6</td>\n",
       "      <td>Transport of organic anions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903810</th>\n",
       "      <td>Q9Y6L6</td>\n",
       "      <td>Metabolism of steroids</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903811</th>\n",
       "      <td>Q9Y6L6</td>\n",
       "      <td>Drug ADME</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903812</th>\n",
       "      <td>Q9Y6L6</td>\n",
       "      <td>Atorvastatin ADME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2439 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       uniprot_id                                  pathway\n",
       "412824     O00255                      Signal Transduction\n",
       "412825     O00255   Signaling by TGF-beta Receptor Complex\n",
       "412826     O00255                 Signaling by Rho GTPases\n",
       "412827     O00255                     RHO GTPase Effectors\n",
       "412828     O00255                         Signaling by WNT\n",
       "...           ...                                      ...\n",
       "903808     Q9Y6L6  Disorders of transmembrane transporters\n",
       "903809     Q9Y6L6              Transport of organic anions\n",
       "903810     Q9Y6L6                   Metabolism of steroids\n",
       "903811     Q9Y6L6                                Drug ADME\n",
       "903812     Q9Y6L6                        Atorvastatin ADME\n",
       "\n",
       "[2439 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  biological pathways that may be affected by the interaction of a molecule with its targets. \n",
    "# ! still need to make sure all the non human genes are turned into human orthologs\n",
    "reactome_df[reactome_df['uniprot_id'].isin(chemble_B1_target_uniprot)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C4: biological processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DB': 'UniProtKB', 'DB_Object_ID': 'A0A024QZ33', 'DB_Object_Symbol': 'NSRP1', 'Qualifier': ['involved_in'], 'GO_ID': 'GO:0000381', 'DB:Reference': ['GO_REF:0000002'], 'Evidence': 'IEA', 'With': ['InterPro:IPR018612'], 'Aspect': 'P', 'DB_Object_Name': 'Nuclear speckle splicing regulatory protein 1', 'Synonym': ['NSRP1', 'CCDC55', 'hCG_1646942'], 'DB_Object_Type': 'protein', 'Taxon_ID': ['9606'], 'Date': '20220907', 'Assigned_By': 'InterPro', 'Annotation_Extension': '', 'Gene_Product_Form_ID': ''}\n"
     ]
    }
   ],
   "source": [
    "with open('../GOA/25.H_sapiens.goa', 'r') as handle:\n",
    "\n",
    "    for rec in gafiterator(handle):\n",
    "        print(rec)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['enables']\n",
      "GO:0004064\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['enables']\n",
      "GO:0004089\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['enables']\n",
      "GO:0004089\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['enables']\n",
      "GO:0004089\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['enables']\n",
      "GO:0004089\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['enables']\n",
      "GO:0004089\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['enables']\n",
      "GO:0004089\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['enables']\n",
      "GO:0005515\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['enables']\n",
      "GO:0005515\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['enables']\n",
      "GO:0008270\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['enables']\n",
      "GO:0016829\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['enables']\n",
      "GO:0016836\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['enables']\n",
      "GO:0016836\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['enables']\n",
      "GO:0018820\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['enables']\n",
      "GO:0046872\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['involved_in']\n",
      "GO:0006730\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['involved_in']\n",
      "GO:0006730\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['is_active_in']\n",
      "GO:0005737\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['located_in']\n",
      "GO:0005737\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['located_in']\n",
      "GO:0005737\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['located_in']\n",
      "GO:0005737\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['located_in']\n",
      "GO:0005829\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['located_in']\n",
      "GO:0005829\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['located_in']\n",
      "GO:0005829\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['located_in']\n",
      "GO:0005829\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['located_in']\n",
      "GO:0005829\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['located_in']\n",
      "GO:0005829\n",
      "====================\n",
      "P00915\n",
      "Carbonic anhydrase 1\n",
      "['located_in']\n",
      "GO:0070062\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "# We downloaded the Gene Ontology Annotation database (https://www.ebi.ac.uk/GOA, May 2017)\n",
    "# read the ‘biological process’ branch of the ontology as a directed acyclic graph (‘is a’ relationships). \n",
    "# Proteins were annotated with their Gene Ontology Annotation biological process terms plus parent terms (up to the root of the directed acyclic graph). \n",
    "# Similar to C3, we associated molecules with biological process terms by simply checking the annotations of the molecule targets (B4).\n",
    "from ast import And\n",
    "from Bio.UniProt.GOA import gafiterator, record_has\n",
    "\n",
    "for x in chemble_B1_target_uniprot.to_list():\n",
    "    Interpro_ID = {'With': set([f'InterPro:IPR018612'])} \n",
    "    DB_Object_ID = {'DB_Object_ID': set([x])} \n",
    "\n",
    "    # DB_Object_name = {'DB_Object_name' : set(['Nuclear speckle splicing regulatory protein 1'])} \n",
    "\n",
    "    with open('../GOA/25.H_sapiens.goa', 'r') as handle:\n",
    "\n",
    "        for rec in gafiterator(handle):\n",
    "            if record_has(rec, DB_Object_ID):\n",
    "                for key in ('DB_Object_ID','DB_Object_Name', 'Qualifier', 'GO_ID'):\n",
    "                    print(rec[key])\n",
    "                print('='*20)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C5: interactomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We collected five representative PPI networks, \n",
    "# namely STRING (score of >700, that is, high confidence)63 (v.10, https://string-db.org) (14,725 proteins (p), 300,686 interactions (i)), #! waiting for data\n",
    "# InWeb (score of 0.5)64 (http://www.intomics.com/inbio/map, March 2017) (10,100 p, 168,970 i), #!paid service? <- not gonna use\n",
    "# a portion of Pathway Commons containing interactions from known pathways (Kyoto Encylopedia of Genes and Genomes65, NetPath66, PANTHER67 and WikiPathways68) (9,344 p, 242,962 i), #!need to find out\n",
    "# an in-house network of physical binary PPIs69 (13,038 p, 64,659 i),  #!need to find in house pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def influence_node(input_array, r_min=0, r_max=10): #maximum of the range of your measurement\n",
    "    input_max = np.amax(input_array) #maximum of the range of your desired target scaling\n",
    "    input_min = np.amin(input_array) #minimum of the range of your desired target scaling\n",
    "    output = np.ndarray.round((input_array - input_min) / (input_max - input_min) * (r_max - r_min) + r_min)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stringDB_uniprot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m drugbank_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mDB/drugbank_extracted.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m target_list_uniprot \u001b[39m=\u001b[39m drugbank_df[drugbank_df[\u001b[39m\"\u001b[39m\u001b[39mdg_name\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m==\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAcetazolamide\u001b[39m\u001b[39m\"\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mtarget_uniprot\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m----> 3\u001b[0m target_list \u001b[39m=\u001b[39m stringDB_uniprot[stringDB_uniprot[\u001b[39m'\u001b[39m\u001b[39mprotein1_uniprot_id\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39misin(target_list_uniprot)][\u001b[39m'\u001b[39m\u001b[39mprotein1\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()\u001b[39m.\u001b[39mtolist()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stringDB_uniprot' is not defined"
     ]
    }
   ],
   "source": [
    "drugbank_df = pd.read_csv(\"DB/drugbank_extracted.csv\")\n",
    "target_list_uniprot = drugbank_df[drugbank_df[\"dg_name\"]==\"Acetazolamide\"]['target_uniprot'].tolist()\n",
    "target_list = stringDB_uniprot[stringDB_uniprot['protein1_uniprot_id'].isin(target_list_uniprot)]['protein1'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/78/zn54_c9d2jb_8j8xx5s59dqw0000gn/T/ipykernel_34974/1745851512.py:2: DtypeWarning: Columns (5,7,8,9,10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  chemble_B1 = pd.read_csv(\"../chembl31forlinfeng/B1_data.csv\", sep=',', header=0)\n",
      "/var/folders/78/zn54_c9d2jb_8j8xx5s59dqw0000gn/T/ipykernel_34974/1745851512.py:3: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  chemble_B4B5 = pd.read_csv(\"../chembl31forlinfeng/B4B5_data.csv\", sep=',', header=0)\n"
     ]
    }
   ],
   "source": [
    "#determine weight using assay data from B4\n",
    "chemble_B1 = pd.read_csv(\"../chembl31forlinfeng/B1_data.csv\", sep=',', header=0)\n",
    "chemble_B4B5 = pd.read_csv(\"../chembl31forlinfeng/B4B5_data.csv\", sep=',', header=0)\n",
    "chemble_B4B5_ic50 = chemble_B4B5[chemble_B4B5['standard_type']=='IC50'] #B4\n",
    "\n",
    "ion_channels = ['Ligand-gated ion channel','Voltage-gated ion channel', 'Other ion channel']\n",
    "g_protein = ['Family A G protein-coupled receptor', 'Family C G protein-coupled receptor',\n",
    "            'Family B G protein-coupled receptor','Frizzled family G protein-coupled receptor',\n",
    "            'Taste family G protein-coupled receptor']\n",
    "\n",
    "not_other = ['Ligand-gated ion channel','Voltage-gated ion channel', 'Other ion channel'\n",
    "            'Family A G protein-coupled receptor', 'Family C G protein-coupled receptor',\n",
    "            'Family B G protein-coupled receptor','Frizzled family G protein-coupled receptor',\n",
    "            'Taste family G protein-coupled receptor', 'Kinase','Nuclear receptor']\n",
    "# kinases ≤30 nM, \n",
    "kinase_df = chemble_B1[chemble_B1['l2']==\"Kinase\"]\n",
    "kinase_ic = chemble_B4B5_ic50[chemble_B4B5_ic50['uniprot_id'].isin(kinase_df['uniprot_id'])]\n",
    "kinase_ic_filter = chemble_B4B5_ic50[chemble_B4B5_ic50['standard_value']<=30]\n",
    "# G protein-coupled receptors ≤100 nM, \n",
    "g_protein_df = chemble_B1[chemble_B1['l2'].isin(g_protein)]\n",
    "g_protein_ic = chemble_B4B5_ic50[chemble_B4B5_ic50['uniprot_id'].isin(g_protein_df['uniprot_id'])]\n",
    "g_protein_ic_filter = chemble_B4B5_ic50[chemble_B4B5_ic50['standard_value']<=100]\n",
    "# nuclear receptors ≤100 nM,  \n",
    "nuclear_receptor_df = chemble_B1[chemble_B1['l2']=='Nuclear receptor']\n",
    "nuclear_receptor_ic = chemble_B4B5_ic50[chemble_B4B5_ic50['uniprot_id'].isin(nuclear_receptor_df['uniprot_id'])]\n",
    "nuclear_receptor_ic_filter = chemble_B4B5_ic50[chemble_B4B5_ic50['standard_value']<=100]\n",
    "# ion channels ≤10 μM\n",
    "ion_channel_df = chemble_B1[chemble_B1['l2'].isin(ion_channels)]\n",
    "ion_channel_ic = chemble_B4B5_ic50[chemble_B4B5_ic50['uniprot_id'].isin(ion_channel_df['uniprot_id'])]\n",
    "ion_channel_ic_filter = chemble_B4B5_ic50[chemble_B4B5_ic50['standard_value']<=1000]\n",
    "# others ≤1 μM. \n",
    "\n",
    "others_df = chemble_B1[~chemble_B1['l2'].isin(not_other)]\n",
    "other_ic = chemble_B4B5_ic50[chemble_B4B5_ic50['uniprot_id'].isin(others_df['uniprot_id'])] #!数据重复是怎么回事\n",
    "other_ic_filter = other_ic[other_ic['standard_value']<=1000]\n",
    "# We also kept activities one order of magnitude lower than the class-specific cutoff (to a maximum of 10 μM), \n",
    "# and gave these annotations half the weight in downstream analyses (that is, log10 scaling)\n",
    "\n",
    "in_threshold = pd.concat([kinase_ic_filter, g_protein_ic_filter,nuclear_receptor_ic_filter,ion_channel_ic_filter,other_ic_filter])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### StringDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>protein1</th>\n",
       "      <th>protein2</th>\n",
       "      <th>neighborhood</th>\n",
       "      <th>fusion</th>\n",
       "      <th>cooccurence</th>\n",
       "      <th>coexpression</th>\n",
       "      <th>experimental</th>\n",
       "      <th>database</th>\n",
       "      <th>textmining</th>\n",
       "      <th>combined_score</th>\n",
       "      <th>protein1_uniprot_id</th>\n",
       "      <th>protein1_protein_name</th>\n",
       "      <th>protein2_uniprot_id</th>\n",
       "      <th>protein2_protein_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000324287</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>736</td>\n",
       "      <td>767</td>\n",
       "      <td>P84085</td>\n",
       "      <td>ADP-ribosylation factor 5</td>\n",
       "      <td>Q15057</td>\n",
       "      <td>Arf-GAP with coiled-coil, ANK repeat and PH do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000387286</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>79</td>\n",
       "      <td>248</td>\n",
       "      <td>600</td>\n",
       "      <td>141</td>\n",
       "      <td>730</td>\n",
       "      <td>P84085</td>\n",
       "      <td>ADP-ribosylation factor 5</td>\n",
       "      <td>P62820</td>\n",
       "      <td>Ras-related protein Rab-1A (EC 3.6.5.2) (YPT1-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000262812</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>163</td>\n",
       "      <td>600</td>\n",
       "      <td>173</td>\n",
       "      <td>745</td>\n",
       "      <td>P84085</td>\n",
       "      <td>ADP-ribosylation factor 5</td>\n",
       "      <td>O14579</td>\n",
       "      <td>Coatomer subunit epsilon (Epsilon-coat protein...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000158762</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "      <td>736</td>\n",
       "      <td>765</td>\n",
       "      <td>P84085</td>\n",
       "      <td>ADP-ribosylation factor 5</td>\n",
       "      <td>Q15027</td>\n",
       "      <td>Arf-GAP with coiled-coil, ANK repeat and PH do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9606.ENSP00000000233</td>\n",
       "      <td>9606.ENSP00000449270</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>210</td>\n",
       "      <td>600</td>\n",
       "      <td>194</td>\n",
       "      <td>757</td>\n",
       "      <td>P84085</td>\n",
       "      <td>ADP-ribosylation factor 5</td>\n",
       "      <td>P61923</td>\n",
       "      <td>Coatomer subunit zeta-1 (Zeta-1-coat protein) ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               protein1              protein2  neighborhood  fusion  \\\n",
       "0  9606.ENSP00000000233  9606.ENSP00000324287             0       0   \n",
       "1  9606.ENSP00000000233  9606.ENSP00000387286             0       0   \n",
       "2  9606.ENSP00000000233  9606.ENSP00000262812             0       0   \n",
       "3  9606.ENSP00000000233  9606.ENSP00000158762             0       0   \n",
       "4  9606.ENSP00000000233  9606.ENSP00000449270             0       0   \n",
       "\n",
       "   cooccurence  coexpression  experimental  database  textmining  \\\n",
       "0            0            49           147         0         736   \n",
       "1            0            79           248       600         141   \n",
       "2            0           190           163       600         173   \n",
       "3            0             0           147         0         736   \n",
       "4            0           162           210       600         194   \n",
       "\n",
       "   combined_score protein1_uniprot_id      protein1_protein_name  \\\n",
       "0             767              P84085  ADP-ribosylation factor 5   \n",
       "1             730              P84085  ADP-ribosylation factor 5   \n",
       "2             745              P84085  ADP-ribosylation factor 5   \n",
       "3             765              P84085  ADP-ribosylation factor 5   \n",
       "4             757              P84085  ADP-ribosylation factor 5   \n",
       "\n",
       "  protein2_uniprot_id                              protein2_protein_name  \n",
       "0              Q15057  Arf-GAP with coiled-coil, ANK repeat and PH do...  \n",
       "1              P62820  Ras-related protein Rab-1A (EC 3.6.5.2) (YPT1-...  \n",
       "2              O14579  Coatomer subunit epsilon (Epsilon-coat protein...  \n",
       "3              Q15027  Arf-GAP with coiled-coil, ANK repeat and PH do...  \n",
       "4              P61923  Coatomer subunit zeta-1 (Zeta-1-coat protein) ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stringDB_uniprot = pd.read_csv('../human_HighConfidence_string_PPI_add_uniprot.csv')\n",
    "stringDB_uniprot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stringDB_df = pd.read_csv('../human_HighConfidence_string_PPI.csv', sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating hotnet input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create input for hotnet -stringDB\n",
    "bla = np.append(stringDB_df['protein1'].unique(), stringDB_df['protein2'].unique()) #this needs to be done as there are unique prot in prot2 that don't exist in prot1\n",
    "bla = set(bla.tolist())\n",
    "\n",
    "protein_encoding = {}\n",
    "\n",
    "for i, x in enumerate(bla):\n",
    "    protein_encoding[x] = i+1\n",
    "protein1_encoding = []\n",
    "for x in stringDB_df['protein1']:\n",
    "    protein1_encoding.append(protein_encoding[x])\n",
    "    \n",
    "protein2_encoding = []\n",
    "for x in stringDB_df['protein2']:\n",
    "    protein2_encoding.append(protein_encoding[x])\n",
    "    \n",
    "stringDB_df['protein1_encoding'] = protein1_encoding\n",
    "stringDB_df['protein2_encoding'] = protein2_encoding\n",
    "\n",
    "protein_encoding = pd.DataFrame({'Names':list(protein_encoding.keys()), 'Encodings':list(protein_encoding.values())})\n",
    "\n",
    "#export index file\n",
    "protein_encoding[['Encodings','Names']].to_csv('stringDB_index.txt', sep = \" \", index = False, index_label = False, header = False)\n",
    "stringDB_df[['protein1_encoding','protein2_encoding']].to_csv('stringDB_edge.txt', sep = \" \", index = False, index_label = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = np.append(stringDB_uniprot['protein1_uniprot_id'].unique(), stringDB_uniprot['protein2_uniprot_id'].unique()) #this needs to be done as there are unique prot in prot2 that don't exist in prot1\n",
    "bla = set(bla.tolist())\n",
    "\n",
    "protein_encoding = {}\n",
    "\n",
    "for i, x in enumerate(bla):\n",
    "    protein_encoding[x] = i+1\n",
    "protein1_encoding = []\n",
    "for x in stringDB_uniprot['protein1_uniprot_id']:\n",
    "    protein1_encoding.append(protein_encoding[x])\n",
    "    \n",
    "protein2_encoding = []\n",
    "for x in stringDB_uniprot['protein2_uniprot_id']:\n",
    "    protein2_encoding.append(protein_encoding[x])\n",
    "    \n",
    "stringDB_uniprot['protein1_encoding'] = protein1_encoding\n",
    "stringDB_uniprot['protein2_encoding'] = protein2_encoding\n",
    "\n",
    "stringDB_uniprot = stringDB_uniprot[stringDB_uniprot['protein2_uniprot_id']!='nan']\n",
    "stringDB_uniprot = stringDB_uniprot[stringDB_uniprot['protein1_uniprot_id']!='nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1 = stringDB_uniprot['protein1_uniprot_id'].unique()\n",
    "arr2 = stringDB_uniprot['protein2_uniprot_id'].unique()\n",
    "arr3 = np.concatenate((arr1, arr2))\n",
    "stringDB_uniprot_conv = stringDB_uniprot[stringDB_uniprot['protein1_uniprot_id'].isin(arr3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! Not used\n",
    "# #create input for hotnet -stringDB\n",
    "# bla = np.append(stringDB_uniprot['protein1_uniprot_id'].unique(), stringDB_uniprot['protein2_uniprot_id'].unique()) #this needs to be done as there are unique prot in prot2 that don't exist in prot1\n",
    "# bla = set(bla.tolist())\n",
    "\n",
    "# protein_encoding = {}\n",
    "\n",
    "# for i, x in enumerate(bla):\n",
    "#     protein_encoding[x] = i+1\n",
    "# protein1_encoding = []\n",
    "# for x in stringDB_uniprot['protein1_uniprot_id']:\n",
    "#     protein1_encoding.append(protein_encoding[x])\n",
    "    \n",
    "# protein2_encoding = []\n",
    "# for x in stringDB_uniprot['protein2_uniprot_id']:\n",
    "#     protein2_encoding.append(protein_encoding[x])\n",
    "    \n",
    "# stringDB_uniprot['protein1_encoding'] = protein1_encoding\n",
    "# stringDB_uniprot['protein2_encoding'] = protein2_encoding\n",
    "\n",
    "# protein_encoding = pd.DataFrame({'Names':list(protein_encoding.keys()), 'Encodings':list(protein_encoding.values())})\n",
    "\n",
    "# #export index file\n",
    "# protein_encoding[['Encodings','Names']].to_csv('stringDB_index1.txt', sep = \" \", index = False, index_label = False, header = False)\n",
    "# stringDB_uniprot[['protein1_encoding','protein2_encoding']].to_csv('stringDB_edge1.txt', sep = \" \", index = False, index_label = False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening H5 and get the influence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['PPR', 'beta', 'edges', 'network_name', 'nodes']>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File('/Users/linfengwang/Github/linfeng-wang-CCdatabase/hotnet_output/stringDB_mat_ppr_0.6.h5', \"r\") as hdf:\n",
    "    # Print all root level object names (aka keys) \n",
    "    # these can be group or dataset names \n",
    "    print(\"Keys: %s\" % hdf.keys())\n",
    "    PPR = hdf.get('PPR')\n",
    "    PPR_dataset = np.array(PPR)\n",
    "    \n",
    "    edges = hdf.get('edges') #sample name, given in pairs\n",
    "    edges_dataset = np.array(edges)\n",
    "\n",
    "    nodes = hdf.get('nodes') #individual sample names\n",
    "    nodes_dataset = np.array(nodes) \n",
    "\n",
    "    network_name = hdf.get('network_name') #name of the network\n",
    "    network_name_dataset = np.array(network_name)\n",
    "    beta = hdf.get('beta') #version beta\n",
    "    beta_dataset = np.array(beta)\n",
    "\n",
    "    # # get first object name/key; may or may NOT be a group\n",
    "    # a_group_key = list(f.keys())[0]\n",
    "\n",
    "    # # get the object type for a_group_key: usually group or dataset\n",
    "    # print(type(f[a_group_key])) \n",
    "\n",
    "    # # If a_group_key is a group name, \n",
    "    # # this gets the object names in the group and returns as a list\n",
    "    # data = list(f[a_group_key])\n",
    "\n",
    "    # # If a_group_key is a dataset name, \n",
    "    # # this gets the dataset values and returns as a list\n",
    "    # data = list(f[a_group_key])\n",
    "    # # preferred methods to get dataset values:\n",
    "    # ds_obj = f[a_group_key]      # returns as a h5py dataset object\n",
    "    # ds_arr = f[a_group_key][()]  # returns as a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list_stringDB = stringDB_uniprot[stringDB_uniprot['protein1_uniprot_id'].isin(target_list_uniprot)]['protein1'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_edge = []\n",
    "for target in target_list_stringDB:\n",
    "    for x in edges_dataset:\n",
    "        # print(x[0].decode('ascii'))\n",
    "        if x[0].decode('ascii') == target:\n",
    "            target_edge.append(x)\n",
    "        # elif x[1].decode('ascii') == target:\n",
    "        #     target_edge.append(x)\n",
    "\n",
    "# is is only protein1 influencing protein2 right? \n",
    "            \n",
    "# #convert the edge name to index\n",
    "target_edge_coord = []\n",
    "for x in target_edge:\n",
    "    coord = ['nan', 'nan']\n",
    "    for i, y in enumerate(nodes_dataset):\n",
    "        if x[0] == y:\n",
    "            coord[0]=i\n",
    "        if x[1] == y:\n",
    "            coord[1]=i\n",
    "    target_edge_coord.append(coord)\n",
    "    \n",
    "# #convert the edge name to index using dictionary\n",
    "# target_edge_coord = {}\n",
    "# for x in target_edge:\n",
    "#     target_edge_coord[x.tolist()] = ['nan', 'nan']\n",
    "#     for i, y in enumerate(nodes_dataset):\n",
    "#         if x[0] == y:\n",
    "#             target_edge_coord[x]=i\n",
    "#         if x[1] == y:\n",
    "#             target_edge_coord[x]=i\n",
    "    \n",
    "#interaction values extraction using coordinates\n",
    "\n",
    "interaction_values = []\n",
    "for x in target_edge_coord:\n",
    "    interaction_values.append(PPR_dataset[x[0],x[1]])\n",
    "\n",
    "#scale interaction values to between 0 and 10\n",
    "influence_values = influence_node(interaction_values)\n",
    "\n",
    "\n",
    "# Then, for each target of a certain compound, we kept proteins with a non-0 influence score (the target itself was given a score of ten  and, when one protein was influenced by more than one target, the maximum score was kept). \n",
    "influenced_stringDB = {}\n",
    "for x, y in zip(interaction_values, target_edge):\n",
    "    if x == 0:\n",
    "        continue\n",
    "    if y[1] not in influenced_stringDB.keys():\n",
    "        influenced_stringDB[y[1]] = x\n",
    "    else:\n",
    "        if influenced_stringDB[y[1]] < x:\n",
    "            influenced_stringDB[y[1]] = x\n",
    "        else:\n",
    "            continue\n",
    "    if y[0] not in influenced_stringDB.keys():\n",
    "        influenced_stringDB[y[0]] = 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding weight from B4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_threshold = pd.concat([kinase_ic_filter, g_protein_ic_filter,nuclear_receptor_ic_filter,ion_channel_ic_filter,other_ic_filter])\n",
    "\n",
    "# Finally, these scores were multiplied by the weight of the compound-target annotation (see B4). \n",
    "#is everthing that with in class specific cut of multiplied by 1 and everything outside the class specific cutoff multiplied by log10\n",
    "for k, v in influenced_stringDB.items():\n",
    "    string_code = k.decode('ascii')\n",
    "    uniprot_code = stringDB_uniprot_conv[stringDB_uniprot_conv['protein1']==string_code]['protein1_uniprot_id'].unique()[0]\n",
    "    # uniprot = stringDB_uniprot[stringDB_uniprot['protein1_uniprot_id']==uniprot_code]['protein1_uniprot_id'].unique()[0]\n",
    "    if uniprot_code in in_threshold['uniprot_id'].unique():\n",
    "        continue\n",
    "    else:\n",
    "        influenced_stringDB[k] = np.log10(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'9606.ENSP00000216862': 0.015335382,\n",
       " b'9606.ENSP00000178638': 10,\n",
       " b'9606.ENSP00000300900': 0.0425477,\n",
       " b'9606.ENSP00000262418': -1.8118263,\n",
       " b'9606.ENSP00000285379': 10,\n",
       " b'9606.ENSP00000295256': 0.0023837313,\n",
       " b'9606.ENSP00000250559': -2.6582344,\n",
       " b'9606.ENSP00000382004': -2.7136254,\n",
       " b'9606.ENSP00000265686': -2.3814678,\n",
       " b'9606.ENSP00000261769': -2.916688,\n",
       " b'9606.ENSP00000393557': -1.6337378,\n",
       " b'9606.ENSP00000373620': 0.0017948113,\n",
       " b'9606.ENSP00000378920': -1.635768,\n",
       " b'9606.ENSP00000304669': -2.6967418,\n",
       " b'9606.ENSP00000366641': -1.5092093,\n",
       " b'9606.ENSP00000285381': 10,\n",
       " b'9606.ENSP00000358107': 0.1276431,\n",
       " b'9606.ENSP00000367608': 0.017717116,\n",
       " b'9606.ENSP00000405899': -1.5747824,\n",
       " b'9606.ENSP00000311165': 1.0,\n",
       " b'9606.ENSP00000264938': 0.009327489,\n",
       " b'9606.ENSP00000318355': -1.4979736,\n",
       " b'9606.ENSP00000220764': -1.9046055,\n",
       " b'9606.ENSP00000345659': 10,\n",
       " b'9606.ENSP00000300215': -1.707651,\n",
       " b'9606.ENSP00000430656': 10,\n",
       " b'9606.ENSP00000427690': -1.6068602,\n",
       " b'9606.ENSP00000376134': -2.5585365}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "influenced_stringDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interaction3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROT1</th>\n",
       "      <th>PROT2</th>\n",
       "      <th>RANK_MAJOR</th>\n",
       "      <th>RANK_MINOR</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>PDB_ID</th>\n",
       "      <th>BIO_UNIT</th>\n",
       "      <th>CHAIN1</th>\n",
       "      <th>MODEL1</th>\n",
       "      <th>SEQ_IDENT1</th>\n",
       "      <th>...</th>\n",
       "      <th>SEQ_END1</th>\n",
       "      <th>DOMAIN1</th>\n",
       "      <th>CHAIN2</th>\n",
       "      <th>MODEL2</th>\n",
       "      <th>SEQ_IDENT2</th>\n",
       "      <th>COVERAGE2</th>\n",
       "      <th>SEQ_BEGIN2</th>\n",
       "      <th>SEQ_END2</th>\n",
       "      <th>DOMAIN2</th>\n",
       "      <th>FILENAME</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A0A024RAV5</td>\n",
       "      <td>P02647</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Structure</td>\n",
       "      <td>2mse</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>185</td>\n",
       "      <td>-</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>74.2</td>\n",
       "      <td>68</td>\n",
       "      <td>265</td>\n",
       "      <td>-</td>\n",
       "      <td>A0A024RAV5-P02647-EXP-2mse.pdb1-B-0-A-0.pdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A0A024RAV5</td>\n",
       "      <td>P02647</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Structure</td>\n",
       "      <td>6pts</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>185</td>\n",
       "      <td>-</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>74.2</td>\n",
       "      <td>68</td>\n",
       "      <td>265</td>\n",
       "      <td>-</td>\n",
       "      <td>A0A024RAV5-P02647-EXP-6pts.pdb1-B-0-A-0.pdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A0A024RAV5</td>\n",
       "      <td>P10398</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Structure</td>\n",
       "      <td>2mse</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>185</td>\n",
       "      <td>-</td>\n",
       "      <td>D</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>19</td>\n",
       "      <td>91</td>\n",
       "      <td>-</td>\n",
       "      <td>A0A024RAV5-P10398-EXP-2mse.pdb1-B-0-D-0.pdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A0A075B5G3</td>\n",
       "      <td>Q8NBP7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Structure</td>\n",
       "      <td>4ov6</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>-</td>\n",
       "      <td>B</td>\n",
       "      <td>0</td>\n",
       "      <td>95.6</td>\n",
       "      <td>42.5</td>\n",
       "      <td>153</td>\n",
       "      <td>446</td>\n",
       "      <td>-</td>\n",
       "      <td>A0A075B5G3-Q8NBP7-EXP-4ov6.pdb1-F-0-B-0.pdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A0A075B5G3</td>\n",
       "      <td>Q8NBP7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Structure</td>\n",
       "      <td>4ov6</td>\n",
       "      <td>2</td>\n",
       "      <td>G</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>-</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "      <td>92.2</td>\n",
       "      <td>42.3</td>\n",
       "      <td>153</td>\n",
       "      <td>445</td>\n",
       "      <td>-</td>\n",
       "      <td>A0A075B5G3-Q8NBP7-EXP-4ov6.pdb2-G-0-E-0.pdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124919</th>\n",
       "      <td>V9HW83</td>\n",
       "      <td>V9HW83</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>Structure</td>\n",
       "      <td>4wb9</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>501</td>\n",
       "      <td>-</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.4</td>\n",
       "      <td>9</td>\n",
       "      <td>501</td>\n",
       "      <td>-</td>\n",
       "      <td>V9HW83-V9HW83-EXP-4wb9.pdb1-A-2-A-3.pdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124920</th>\n",
       "      <td>V9HW83</td>\n",
       "      <td>V9HW83</td>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>Structure</td>\n",
       "      <td>4wb9</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>501</td>\n",
       "      <td>-</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.4</td>\n",
       "      <td>9</td>\n",
       "      <td>501</td>\n",
       "      <td>-</td>\n",
       "      <td>V9HW83-V9HW83-EXP-4wb9.pdb1-A-0-A-1.pdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124921</th>\n",
       "      <td>V9HW83</td>\n",
       "      <td>V9HW83</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>Structure</td>\n",
       "      <td>4wb9</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>501</td>\n",
       "      <td>-</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.4</td>\n",
       "      <td>9</td>\n",
       "      <td>501</td>\n",
       "      <td>-</td>\n",
       "      <td>V9HW83-V9HW83-EXP-4wb9.pdb1-A-0-A-2.pdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124922</th>\n",
       "      <td>V9HW83</td>\n",
       "      <td>V9HW83</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>Structure</td>\n",
       "      <td>4wb9</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>501</td>\n",
       "      <td>-</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.4</td>\n",
       "      <td>9</td>\n",
       "      <td>501</td>\n",
       "      <td>-</td>\n",
       "      <td>V9HW83-V9HW83-EXP-4wb9.pdb1-A-0-A-3.pdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124923</th>\n",
       "      <td>V9HW83</td>\n",
       "      <td>V9HW83</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>Structure</td>\n",
       "      <td>4wb9</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>100.0</td>\n",
       "      <td>...</td>\n",
       "      <td>501</td>\n",
       "      <td>-</td>\n",
       "      <td>A</td>\n",
       "      <td>3</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.4</td>\n",
       "      <td>9</td>\n",
       "      <td>501</td>\n",
       "      <td>-</td>\n",
       "      <td>V9HW83-V9HW83-EXP-4wb9.pdb1-A-1-A-3.pdb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124923 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PROT1   PROT2 RANK_MAJOR RANK_MINOR       TYPE PDB_ID BIO_UNIT  \\\n",
       "1       A0A024RAV5  P02647          1          0  Structure   2mse        1   \n",
       "2       A0A024RAV5  P02647          2          0  Structure   6pts        1   \n",
       "3       A0A024RAV5  P10398          1          0  Structure   2mse        1   \n",
       "4       A0A075B5G3  Q8NBP7          1          0  Structure   4ov6        1   \n",
       "5       A0A075B5G3  Q8NBP7          2          0  Structure   4ov6        2   \n",
       "...            ...     ...        ...        ...        ...    ...      ...   \n",
       "124919      V9HW83  V9HW83         54          0  Structure   4wb9        1   \n",
       "124920      V9HW83  V9HW83         55          0  Structure   4wb9        1   \n",
       "124921      V9HW83  V9HW83         56          0  Structure   4wb9        1   \n",
       "124922      V9HW83  V9HW83         57          0  Structure   4wb9        1   \n",
       "124923      V9HW83  V9HW83         58          0  Structure   4wb9        1   \n",
       "\n",
       "       CHAIN1 MODEL1 SEQ_IDENT1  ... SEQ_END1 DOMAIN1 CHAIN2 MODEL2  \\\n",
       "1           B      0      100.0  ...      185       -      A      0   \n",
       "2           B      0      100.0  ...      185       -      A      0   \n",
       "3           B      0      100.0  ...      185       -      D      0   \n",
       "4           F      0      100.0  ...       99       -      B      0   \n",
       "5           G      0      100.0  ...       96       -      E      0   \n",
       "...       ...    ...        ...  ...      ...     ...    ...    ...   \n",
       "124919      A      2      100.0  ...      501       -      A      3   \n",
       "124920      A      0      100.0  ...      501       -      A      1   \n",
       "124921      A      0      100.0  ...      501       -      A      2   \n",
       "124922      A      0      100.0  ...      501       -      A      3   \n",
       "124923      A      1      100.0  ...      501       -      A      3   \n",
       "\n",
       "       SEQ_IDENT2 COVERAGE2 SEQ_BEGIN2 SEQ_END2 DOMAIN2  \\\n",
       "1           100.0      74.2         68      265       -   \n",
       "2           100.0      74.2         68      265       -   \n",
       "3           100.0      12.0         19       91       -   \n",
       "4            95.6      42.5        153      446       -   \n",
       "5            92.2      42.3        153      445       -   \n",
       "...           ...       ...        ...      ...     ...   \n",
       "124919      100.0      98.4          9      501       -   \n",
       "124920      100.0      98.4          9      501       -   \n",
       "124921      100.0      98.4          9      501       -   \n",
       "124922      100.0      98.4          9      501       -   \n",
       "124923      100.0      98.4          9      501       -   \n",
       "\n",
       "                                           FILENAME  \n",
       "1       A0A024RAV5-P02647-EXP-2mse.pdb1-B-0-A-0.pdb  \n",
       "2       A0A024RAV5-P02647-EXP-6pts.pdb1-B-0-A-0.pdb  \n",
       "3       A0A024RAV5-P10398-EXP-2mse.pdb1-B-0-D-0.pdb  \n",
       "4       A0A075B5G3-Q8NBP7-EXP-4ov6.pdb1-F-0-B-0.pdb  \n",
       "5       A0A075B5G3-Q8NBP7-EXP-4ov6.pdb2-G-0-E-0.pdb  \n",
       "...                                             ...  \n",
       "124919      V9HW83-V9HW83-EXP-4wb9.pdb1-A-2-A-3.pdb  \n",
       "124920      V9HW83-V9HW83-EXP-4wb9.pdb1-A-0-A-1.pdb  \n",
       "124921      V9HW83-V9HW83-EXP-4wb9.pdb1-A-0-A-2.pdb  \n",
       "124922      V9HW83-V9HW83-EXP-4wb9.pdb1-A-0-A-3.pdb  \n",
       "124923      V9HW83-V9HW83-EXP-4wb9.pdb1-A-1-A-3.pdb  \n",
       "\n",
       "[124923 rows x 22 columns]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# an in-house network of physical binary PPIs69 (13,038 p, 64,659 i),  #!need to find in house pipeline\n",
    "import csv\n",
    "# read flash.dat to a list of lists\n",
    "datContent = [i.strip().split() for i in open(\"../interactions_interactome_3d.dat\").readlines()]\n",
    "interaction3D_df = pd.DataFrame(datContent, columns = datContent[0])\n",
    "interaction3D_df = interaction3D_df[1:] \n",
    "interaction3D_df #! how did you get binary PPI interactome info from this?  https://interactome3d.irbbarcelona.org/help.php#interaction_page\n",
    "# https://interactome3d.irbbarcelona.org/help.php#interaction_page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = np.append(interaction3D_df['PROT1'].unique(), interaction3D_df['PROT2'].unique()) #this needs to be done as there are unique prot in prot2 that don't exist in prot1\n",
    "bla = set(bla.tolist())\n",
    "\n",
    "protein_encoding = {}\n",
    "for i, x in enumerate(bla):\n",
    "    protein_encoding[x] = i+1\n",
    "protein1_encoding = []\n",
    "for x in interaction3D_df['PROT1']:\n",
    "    protein1_encoding.append(protein_encoding[x])\n",
    "    \n",
    "protein2_encoding = []\n",
    "for x in interaction3D_df['PROT2']:\n",
    "    protein2_encoding.append(protein_encoding[x])\n",
    "    \n",
    "interaction3D_df['PROT1_encoding'] = protein1_encoding\n",
    "interaction3D_df['PROT2_encoding'] = protein2_encoding\n",
    "\n",
    "protein_encoding = pd.DataFrame({'Names':list(protein_encoding.keys()), 'Encodings':list(protein_encoding.values())})\n",
    "\n",
    "#export index file\n",
    "protein_encoding[['Encodings','Names']].to_csv('interaction3D_index.txt', sep = \" \", index = False, index_label = False, header = False)\n",
    "interaction3D_df[['PROT1_encoding','PROT2_encoding']].to_csv('interaction3D_edge.txt', sep = \" \", index = False, index_label = False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "getting the uniprot correspondance for interactome3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "drugbank_df_nonan = drugbank_df[drugbank_df['pdb_list']!='Nan']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "124923it [14:31:43,  2.39it/s]\n"
     ]
    }
   ],
   "source": [
    "PROT_uniprot = {}\n",
    "for index, row in tqdm(interaction3D_df.iterrows()):\n",
    "    for i, x in drugbank_df_nonan.iterrows():\n",
    "        if x['pdb_list'] == ['Nan']:\n",
    "            continue\n",
    "        # if bool(set(row['PDB_ID']) & set(x['pdb_list'].split(';'))):\n",
    "        if row['PDB_ID'] in x['pdb_list'].split(';'):\n",
    "            PROT_uniprot[row['PROT1']] = x['target_uniprot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "dict = {'Python' : '.py', 'C++' : '.cpp', 'Java' : '.java'}\n",
    "\n",
    "# create a binary pickle file \n",
    "f = open(\"DB/PROT_uniprot.pkl\",\"wb\")\n",
    "\n",
    "# write the python object (dict) to pickle file\n",
    "pickle.dump(PROT_uniprot,f)\n",
    "\n",
    "# close file\n",
    "f.close()\n",
    "\n",
    "infile = open(\"DB/PROT_uniprot.pkl\",'rb')\n",
    "PROT_uniprot = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROT1_uniprot = []\n",
    "PROT2_uniprot = []\n",
    "\n",
    "for x in interaction3D_df['PROT1']:\n",
    "    try:\n",
    "        PROT1_uniprot.append(PROT_uniprot[x])\n",
    "    except:\n",
    "        PROT1_uniprot.append('Nan')\n",
    "        \n",
    "for x in interaction3D_df['PROT2']:\n",
    "    try:\n",
    "        PROT2_uniprot.append(PROT_uniprot[x])\n",
    "    except:\n",
    "        PROT2_uniprot.append('Nan')\n",
    "        \n",
    "interaction3D_df['PROT1_uniprot'] = PROT1_uniprot\n",
    "interaction3D_df['PROT2_uniprot'] = PROT2_uniprot\n",
    "#drop all NA\n",
    "interaction3D_df_drop = interaction3D_df[interaction3D_df['PROT1_uniprot']!='Nan']\n",
    "interaction3D_df_drop = interaction3D_df_drop[interaction3D_df_drop['PROT2_uniprot']!='Nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #produced uniprot matrix cannot be run\n",
    "# bla = np.append(interaction3D_df_drop['PROT1_uniprot'].unique(), interaction3D_df_drop['PROT2_uniprot'].unique()) #this needs to be done as there are unique prot in prot2 that don't exist in prot1\n",
    "# bla = set(bla.tolist())\n",
    "\n",
    "# protein_encoding = {}\n",
    "# for i, x in enumerate(bla):\n",
    "#     protein_encoding[x] = i+1\n",
    "# protein1_encoding = []\n",
    "# for x in interaction3D_df_drop['PROT1_uniprot']:\n",
    "#     protein1_encoding.append(protein_encoding[x])\n",
    "    \n",
    "# protein2_encoding = []\n",
    "# for x in interaction3D_df_drop['PROT2_uniprot']:\n",
    "#     protein2_encoding.append(protein_encoding[x])\n",
    "    \n",
    "# interaction3D_df_drop['PROT1_encoding'] = protein1_encoding\n",
    "# interaction3D_df_drop['PROT2_encoding'] = protein2_encoding\n",
    "\n",
    "# protein_encoding = pd.DataFrame({'Names':list(protein_encoding.keys()), 'Encodings':list(protein_encoding.values())})\n",
    "\n",
    "# #export index file\n",
    "# protein_encoding[['Encodings','Names']].to_csv('interaction3D_index_uniprot.txt', sep = \" \", index = False, index_label = False, header = False)\n",
    "# interaction3D_df_drop[['PROT1_encoding','PROT2_encoding']].to_csv('interaction3D_edge_uniprot.txt', sep = \" \", index = False, index_label = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "bla = np.append(interaction3D_df_drop['PROT1'].unique(), interaction3D_df_drop['PROT2'].unique()) #this needs to be done as there are unique prot in prot2 that don't exist in prot1\n",
    "bla = set(bla.tolist())\n",
    "\n",
    "protein_encoding = {}\n",
    "for i, x in enumerate(bla):\n",
    "    protein_encoding[x] = i+1\n",
    "protein1_encoding = []\n",
    "for x in interaction3D_df_drop['PROT1']:\n",
    "    protein1_encoding.append(protein_encoding[x])\n",
    "    \n",
    "protein2_encoding = []\n",
    "for x in interaction3D_df_drop['PROT2']:\n",
    "    protein2_encoding.append(protein_encoding[x])\n",
    "    \n",
    "interaction3D_df_drop['PROT1_encoding'] = protein1_encoding\n",
    "interaction3D_df_drop['PROT2_encoding'] = protein2_encoding\n",
    "\n",
    "protein_encoding = pd.DataFrame({'Names':list(protein_encoding.keys()), 'Encodings':list(protein_encoding.values())})\n",
    "\n",
    "#export index file\n",
    "protein_encoding[['Encodings','Names']].to_csv('interaction3D_index1.txt', sep = \" \", index = False, index_label = False, header = False)\n",
    "interaction3D_df_drop[['PROT1_encoding','PROT2_encoding']].to_csv('interaction3D_edge1.txt', sep = \" \", index = False, index_label = False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "opening interactome3D h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['PPR', 'beta', 'edges', 'network_name', 'nodes']>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File('/Users/linfengwang/Github/linfeng-wang-CCdatabase/hotnet_output/interaction3D_mat1_ppr_0.6.h5', \"r\") as hdf:\n",
    "    # Print all root level object names (aka keys) \n",
    "    # these can be group or dataset names \n",
    "    print(\"Keys: %s\" % hdf.keys())\n",
    "    PPR = hdf.get('PPR')\n",
    "    PPR_dataset = np.array(PPR)\n",
    "    \n",
    "    edges = hdf.get('edges') #sample name, given in pairs\n",
    "    edges_dataset = np.array(edges)\n",
    "\n",
    "    nodes = hdf.get('nodes') #individual sample names\n",
    "    nodes_dataset = np.array(nodes) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the edges\n",
    "target_edge = []\n",
    "for target in target_list_uniprot:\n",
    "    for x in edges_dataset:\n",
    "        # print(x[0].decode('ascii'))\n",
    "        if PROT_uniprot[x[0].decode('ascii')] == target:\n",
    "            target_edge.append(x)\n",
    "\n",
    "# is is only protein1 influencing protein2 right? \n",
    "\n",
    "# convert the edge name to index using dictionary\n",
    "target_edge_coord = {}\n",
    "for x in target_edge:\n",
    "    target_edge_coord[str(x)] = ['nan', 'nan']\n",
    "    for i, y in enumerate(nodes_dataset):\n",
    "        if x[0] == y:\n",
    "            target_edge_coord[str(x)][0]=i\n",
    "        if x[1] == y:\n",
    "            target_edge_coord[str(x)][1]=i\n",
    "    # target_edge_coord.append(coord)\n",
    "\n",
    "#ALTERNATIVELY\n",
    "# #convert the edge name to index using dictionary\n",
    "# target_edge_coord = {}\n",
    "# for x in target_edge:\n",
    "#     target_edge_coord[x.tolist()] = ['nan', 'nan']\n",
    "#     for i, y in enumerate(nodes_dataset):\n",
    "#         if x[0] == y:\n",
    "#             target_edge_coord[x]=i\n",
    "#         if x[1] == y:\n",
    "#             target_edge_coord[x]=i\n",
    "    \n",
    "#interaction values extraction using coordinates\n",
    "\n",
    "interaction_values = []\n",
    "for x in target_edge_coord.values():\n",
    "    interaction_values.append(PPR_dataset[x[0],x[1]])\n",
    "\n",
    "#scale interaction values to between 0 and 10\n",
    "influence_values = influence_node(interaction_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, for each target of a certain compound, we kept proteins with a non-0 influence score (the target itself was given a score of ten  and, when one protein was influenced by more than one target, the maximum score was kept). \n",
    "influenced_interactome3D = {}\n",
    "for x, y in zip(interaction_values, target_edge):\n",
    "    if x == 0:\n",
    "        continue\n",
    "    if y[1] not in influenced_interactome3D.keys():\n",
    "        influenced_interactome3D[y[1]] = x\n",
    "    else:\n",
    "        if influenced_interactome3D[y[1]] < x:\n",
    "            influenced_interactome3D[y[1]] = x\n",
    "        else:\n",
    "            continue\n",
    "    if y[0] not in influenced_interactome3D.keys():\n",
    "        influenced_interactome3D[y[0]] = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, these scores were multiplied by the weight of the compound-target annotation (see B4). \n",
    "#is everthing that with in class specific cut of multiplied by 1 and everything outside the class specific cutoff multiplied by log10\n",
    "for k, v in influenced_interactome3D.items():\n",
    "    uniprot = stringDB_uniprot[stringDB_uniprot['protein1_uniprot_id']==k.decode('ascii')]['protein1_uniprot_id'].unique()[0]\n",
    "    if uniprot in in_threshold['uniprot_id'].unique():\n",
    "        continue\n",
    "    else:\n",
    "        influenced_interactome3D[k] = np.log10(v)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'O60516': 0.13446733,\n",
       " b'O60573': 10,\n",
       " b'P61769': 0.008864713,\n",
       " b'P30511': 10,\n",
       " b'P04150': 0.02520138,\n",
       " b'O75376': 10,\n",
       " b'P10827': 0.06476477,\n",
       " b'P11473': 0.040337488,\n",
       " b'O15379': 0.25087938,\n",
       " b'P20393': 0.25087938,\n",
       " b'P10828': 0.039287344,\n",
       " b'Q07869': 0.041156508,\n",
       " b'O75469': 0.03423368,\n",
       " b'P55055': 0.031008163,\n",
       " b'P37231': 0.030559424,\n",
       " b'Q03181': 0.03292512,\n",
       " b'P13631': 0.045340285,\n",
       " b'P41182': 0.09091392,\n",
       " b'P63104': 0.009640468,\n",
       " b'Q96RR4': 10,\n",
       " b'P61981': 0.015860165,\n",
       " b'Q99748': 0.13376714,\n",
       " b'O00451': 10,\n",
       " b'P07949': 0.035068553,\n",
       " b'Q00526': 0.031774286,\n",
       " b'P24863': 10,\n",
       " b'Q13618': 0.049756836,\n",
       " b'O95198': 10,\n",
       " b'Q14145': 0.09303577,\n",
       " b'O94782': 0.06762086,\n",
       " b'P51784': 10,\n",
       " b'Q9Y2X8': 0.0076949713,\n",
       " b'Q8ND25': 10,\n",
       " b'P61077': 0.0059611006,\n",
       " b'P51965': 0.013047812,\n",
       " b'Q96LR5': 0.013631028,\n",
       " b'P0CG47': 0.005014507,\n",
       " b'Q16763': 10,\n",
       " b'P0CG48': 0.00410757,\n",
       " b'Q14494': 0.13460352,\n",
       " b'Q9Y5K5': 10}"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "influenced_interactome3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pathway Common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a portion of Pathway Commons containing interactions from known pathways (Kyoto Encylopedia of Genes and Genomes65, NetPath66, PANTHER67 and WikiPathways68) (9,344 p, 242,962 i), #!need to find out\n",
    "panther = pd.read_csv('../C5_PathwayCommons13.panther.hgnc.txt', sep='\\t')\n",
    "netpath = pd.read_csv('../C5_PathwayCommons13.netpath.hgnc.txt', sep = '\\t')\n",
    "wikipath = pd.read_csv('../C5_PathwayCommons.wiki.hgnc.txt', sep='\\t')\n",
    "\n",
    "netpath = netpath[netpath['INTERACTION_DATA_SOURCE']=='NetPath']\n",
    "panther = panther[panther['INTERACTION_DATA_SOURCE']=='PANTHER']\n",
    "pathway_common = pd.concat([panther, netpath])\n",
    "\n",
    "pathway_common = pd.read_csv('../C5_PathwayCommons13.All.hgnc.txt', sep='\\t')\n",
    "\n",
    "pathway_common =pd.concat([pathway_common, wikipath])\n",
    "pathway_common = pathway_common[pathway_common['INTERACTION_DATA_SOURCE'].isin(['NetPath','PANTHER','KEGG','WikiPathways'])]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PARTICIPANT_A</th>\n",
       "      <th>INTERACTION_TYPE</th>\n",
       "      <th>PARTICIPANT_B</th>\n",
       "      <th>INTERACTION_DATA_SOURCE</th>\n",
       "      <th>INTERACTION_PUBMED_ID</th>\n",
       "      <th>PATHWAY_NAMES</th>\n",
       "      <th>MEDIATOR_IDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>A4GALT</td>\n",
       "      <td>catalysis-precedes</td>\n",
       "      <td>ABO</td>\n",
       "      <td>KEGG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Glycosphingolipid biosynthesis - globo series;...</td>\n",
       "      <td>http://pathwaycommons.org/pc13/Catalysis_4f0b2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>A4GALT</td>\n",
       "      <td>catalysis-precedes</td>\n",
       "      <td>AK3</td>\n",
       "      <td>KEGG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Glycosphingolipid biosynthesis - globo series;...</td>\n",
       "      <td>http://pathwaycommons.org/pc13/BiochemicalReac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>A4GALT</td>\n",
       "      <td>catalysis-precedes</td>\n",
       "      <td>ALG13</td>\n",
       "      <td>KEGG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Glycosphingolipid biosynthesis - globo series;...</td>\n",
       "      <td>http://pathwaycommons.org/pc13/BiochemicalReac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>A4GALT</td>\n",
       "      <td>catalysis-precedes</td>\n",
       "      <td>ALG14</td>\n",
       "      <td>KEGG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Glycosphingolipid biosynthesis - globo series;...</td>\n",
       "      <td>http://pathwaycommons.org/pc13/BiochemicalReac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>A4GALT</td>\n",
       "      <td>catalysis-precedes</td>\n",
       "      <td>ALG5</td>\n",
       "      <td>KEGG</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Glycosphingolipid biosynthesis - globo series;...</td>\n",
       "      <td>http://pathwaycommons.org/pc13/Catalysis_d5de5...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PARTICIPANT_A    INTERACTION_TYPE PARTICIPANT_B INTERACTION_DATA_SOURCE  \\\n",
       "350        A4GALT  catalysis-precedes           ABO                    KEGG   \n",
       "351        A4GALT  catalysis-precedes           AK3                    KEGG   \n",
       "352        A4GALT  catalysis-precedes         ALG13                    KEGG   \n",
       "353        A4GALT  catalysis-precedes         ALG14                    KEGG   \n",
       "354        A4GALT  catalysis-precedes          ALG5                    KEGG   \n",
       "\n",
       "    INTERACTION_PUBMED_ID                                      PATHWAY_NAMES  \\\n",
       "350                   NaN  Glycosphingolipid biosynthesis - globo series;...   \n",
       "351                   NaN  Glycosphingolipid biosynthesis - globo series;...   \n",
       "352                   NaN  Glycosphingolipid biosynthesis - globo series;...   \n",
       "353                   NaN  Glycosphingolipid biosynthesis - globo series;...   \n",
       "354                   NaN  Glycosphingolipid biosynthesis - globo series;...   \n",
       "\n",
       "                                          MEDIATOR_IDS  \n",
       "350  http://pathwaycommons.org/pc13/Catalysis_4f0b2...  \n",
       "351  http://pathwaycommons.org/pc13/BiochemicalReac...  \n",
       "352  http://pathwaycommons.org/pc13/BiochemicalReac...  \n",
       "353  http://pathwaycommons.org/pc13/BiochemicalReac...  \n",
       "354  http://pathwaycommons.org/pc13/Catalysis_d5de5...  "
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathway_common.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathway = pd.read_csv('../pathwaycommon_uniprot.txt', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generating input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "with open('../C5_pathway_common_uniprot.json') as f:\n",
    "    # returns JSON object as \n",
    "    # a dictionary\n",
    "    data = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2281449/2281449 [00:02<00:00, 981983.83it/s] \n"
     ]
    }
   ],
   "source": [
    "Uniprot_pc = []\n",
    "HGNC = []\n",
    "for x in tqdm(data):\n",
    "    try:\n",
    "        x['HGNC Symbol']\n",
    "    except:\n",
    "        continue\n",
    "    else:\n",
    "        if len(x['HGNC Symbol']) == 0:\n",
    "            continue\n",
    "        if len(x['HGNC Symbol']) != len(x['UniProt']):\n",
    "            continue\n",
    "        else:\n",
    "            Uniprot_pc.append(x['UniProt'])\n",
    "            HGNC.append(x['HGNC Symbol'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2065533 2065533\n"
     ]
    }
   ],
   "source": [
    "print(len(Uniprot_pc), len(HGNC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont run this twice \n",
    "Uniprot_pc = [item for sublist in Uniprot_pc for item in sublist]\n",
    "HGNC = [item for sublist in HGNC for item in sublist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "Uniprot_HGNC = pd.DataFrame(list(zip(Uniprot_pc, HGNC)), columns =['Uniprot_pc', 'HGNC'])\n",
    "Uniprot_HGNC = Uniprot_HGNC.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "53825it [13:58, 64.18it/s]\n"
     ]
    }
   ],
   "source": [
    "#runs a long time\n",
    "PARTICIPANT_A_uniprot = [0]*(pathway_common.shape[0])\n",
    "PARTICIPANT_B_uniprot = [0]*(pathway_common.shape[0])\n",
    "\n",
    "for i ,(x, y) in tqdm(enumerate(zip(pathway_common['PARTICIPANT_A'],pathway_common['PARTICIPANT_B']))):\n",
    "    rowA = Uniprot_HGNC[Uniprot_HGNC[\"HGNC\"]==x]\n",
    "    rowB = Uniprot_HGNC[Uniprot_HGNC[\"HGNC\"]==y]\n",
    "    # print(i, rowA, rowB)\n",
    "    if len(rowA['Uniprot_pc'].values) > 0:\n",
    "        PARTICIPANT_A_uniprot[i]=rowA['Uniprot_pc'].values[0]\n",
    "    else:\n",
    "        PARTICIPANT_A_uniprot[i]=0\n",
    "        \n",
    "    if len(rowB['Uniprot_pc'].values) > 0:\n",
    "        PARTICIPANT_B_uniprot[i]=rowB['Uniprot_pc'].values[0]\n",
    "    else:\n",
    "        PARTICIPANT_B_uniprot[i]=0 #missing uniprot id are labeled as zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pathway_common.to_csv('DB/pathway_common_uniprot.csv')\n",
    "pathway_common = pd.read_csv('DB/pathway_common_uniprot.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of all the missing uniprot id that are labeled as zero\n",
    "pathway_common = pathway_common[pathway_common['PARTICIPANT_A_uniprot']!=0]\n",
    "pathway_common = pathway_common[pathway_common['PARTICIPANT_B_uniprot']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "protein1_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generating input for hotnet2 using uniprot value\n",
    "bla = np.append(pathway_common['PARTICIPANT_A_uniprot'].unique(), pathway_common['PARTICIPANT_B_uniprot'].unique()) #this needs to be done as there are unique prot in PARTICIPANT_B that don't exist in PARTICIPANT_A\n",
    "bla = set(bla.tolist())\n",
    "\n",
    "protein_encoding = {}\n",
    "for i, x in enumerate(bla):\n",
    "    protein_encoding[x] = i+1\n",
    "protein1_encoding = []\n",
    "for x in pathway_common['PARTICIPANT_A_uniprot']:\n",
    "    protein1_encoding.append(protein_encoding[x])\n",
    "    \n",
    "protein2_encoding = []\n",
    "for x in pathway_common['PARTICIPANT_B_uniprot']:\n",
    "    protein2_encoding.append(protein_encoding[x])\n",
    "    \n",
    "pathway_common['PARTICIPANT_A_encoding'] = protein1_encoding\n",
    "pathway_common['PARTICIPANT_B_encoding'] = protein2_encoding\n",
    "\n",
    "protein_encoding = pd.DataFrame({'Names':list(protein_encoding.keys()), 'Encodings':list(protein_encoding.values())})\n",
    "\n",
    "#export index file\n",
    "protein_encoding[['Encodings','Names']].to_csv('pathway_common_uniprot_index.txt', sep = \" \", index = False, index_label = False, header = False)\n",
    "pathway_common[['PARTICIPANT_A_encoding','PARTICIPANT_B_encoding']].to_csv('pathway_common_uniprot_edge.txt', sep = \" \", index = False, index_label = False, header = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Opening pathway common h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys: <KeysViewHDF5 ['PPR', 'beta', 'edges', 'network_name', 'nodes']>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File('/Users/linfengwang/Github/linfeng-wang-CCdatabase/hotnet_output/pathway_common_uniprot_mat_ppr_0.6.h5', \"r\") as hdf:\n",
    "    # Print all root level object names (aka keys) \n",
    "    # these can be group or dataset names \n",
    "    print(\"Keys: %s\" % hdf.keys())\n",
    "    PPR = hdf.get('PPR')\n",
    "    PPR_dataset = np.array(PPR)\n",
    "    \n",
    "    edges = hdf.get('edges') #sample name, given in pairs\n",
    "    edges_dataset = np.array(edges)\n",
    "\n",
    "    nodes = hdf.get('nodes') #individual sample names\n",
    "    nodes_dataset = np.array(nodes) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the edges\n",
    "target_edge = []\n",
    "for target in target_list_uniprot:\n",
    "    for x in edges_dataset:\n",
    "        # print(x[0].decode('ascii'))\n",
    "        if x[0].decode('ascii') == target:\n",
    "            target_edge.append(x)\n",
    "\n",
    "# convert the edge name to index using dictionary\n",
    "target_edge_coord = {}\n",
    "for x in target_edge:\n",
    "    target_edge_coord[str(x)] = ['nan', 'nan']\n",
    "    for i, y in enumerate(nodes_dataset):\n",
    "        if x[0] == y:\n",
    "            target_edge_coord[str(x)][0]=i\n",
    "        if x[1] == y:\n",
    "            target_edge_coord[str(x)][1]=i\n",
    "    # target_edge_coord.append(coord)\n",
    "\n",
    "interaction_values = []\n",
    "for x in target_edge_coord.values():\n",
    "    interaction_values.append(PPR_dataset[x[0],x[1]])\n",
    "\n",
    "#scale interaction values to between 0 and 10\n",
    "influence_values = influence_node(interaction_values)\n",
    "\n",
    "# Then, for each target of a certain compound, we kept proteins with a non-0 influence score (the target itself was given a score of ten  and, when one protein was influenced by more than one target, the maximum score was kept). \n",
    "influenced_pathwaycommon = {}\n",
    "for x, y in zip(interaction_values, target_edge):\n",
    "    if x == 0:\n",
    "        continue\n",
    "    if y[1] not in influenced_pathwaycommon.keys():\n",
    "        influenced_pathwaycommon[y[1]] = x\n",
    "    else:\n",
    "        if influenced_pathwaycommon[y[1]] < x:\n",
    "            influenced_pathwaycommon[y[1]] = x\n",
    "        else:\n",
    "            continue\n",
    "    if y[0] not in influenced_pathwaycommon.keys():\n",
    "        influenced_pathwaycommon[y[0]] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, these scores were multiplied by the weight of the compound-target annotation (see B4). \n",
    "#is everthing that with in class specific cut of multiplied by 1 and everything outside the class specific cutoff multiplied by log10\n",
    "for k, v in influenced_pathwaycommon.items():\n",
    "    uniprot = stringDB_uniprot[stringDB_uniprot['protein1_uniprot_id']==k.decode('ascii')]['protein1_uniprot_id'].unique()[0]\n",
    "    if uniprot in in_threshold['uniprot_id'].unique():\n",
    "        continue\n",
    "    else:\n",
    "        influenced_pathwaycommon[k] = np.log10(v)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 645,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{b'Q9NZB8': -1.2082998,\n",
       " b'P00915': 10,\n",
       " b'P09622': -2.5057056,\n",
       " b'Q9Y5L3': 0.01193666,\n",
       " b'O60645': -1.1834769,\n",
       " b'P00918': 10,\n",
       " b'O60500': -2.5509589,\n",
       " b'O95267': -2.5228362,\n",
       " b'P41743': 0.0032394952,\n",
       " b'Q15139': 0.00536399}"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "influenced_pathwaycommon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [],
   "source": [
    "influence_concat = {**influenced_stringDB, **influenced_interactome3D, **influenced_pathwaycommon}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recon3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a network of metabolic genes based on Recon (v.2, http://vmh.uni.lu) (1,628 p, 246,937 i). #! recon https://www.vmh.life/#home matlab file?\n",
    "import scipy.io\n",
    "Recon3DModel_mat =  ('../Recon3D_301/Recon3DModel_301.mat')\n",
    "Recon3D_mat = scipy.io.loadmat('../Recon3D_301/Recon3D_301.mat')\n",
    "\n",
    "# To build this last network, we linked two metabolic proteins (enzymes or transporters) when the product metabolite of the first was the substrate of the second, \n",
    "# or when both were needed to perform a certain reaction, suggesting that they are part of the same protein complex. \n",
    "# Edges between proteins were weighted inversely proportional to the number of reactions involving their shared metabolites, \n",
    "# so that ‘currency’ metabolites such as ATP and water had marginal impact on the network connectivity. To control for indirect associations, \n",
    "# we deconvoluted the network using edge weights and setting a network deconvolution score cutoff of 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['__header__', '__version__', '__globals__', 'Recon3D'])"
      ]
     },
     "execution_count": 649,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "Recon3D_mat.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('DB/recon_3d.txt', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    for x in range(1,len(Recon3D_mat['Recon3D'][0][0])):\n",
    "        writer.writerow(Recon3D_mat['Recon3D'][0][0][x].tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Recon3D_mat['Recon3D'][0][0][6].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[array(['10FTHF5GLUtl'], dtype='<U12')],\n",
       "       [array(['10FTHF5GLUtm'], dtype='<U12')],\n",
       "       [array(['10FTHF6GLUtl'], dtype='<U12')],\n",
       "       ...,\n",
       "       [array(['NADH2_u10mi'], dtype='<U11')],\n",
       "       [array(['CYOOm3i'], dtype='<U7')],\n",
       "       [array(['CYOOm2i'], dtype='<U7')]], dtype=object)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Recon3D_mat['Recon3D'][0][0][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8399"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Recon3D_mat['Recon3D'][0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Recon3DModel_mat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [283], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Recon3DModel_mat\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Recon3DModel_mat' is not defined"
     ]
    }
   ],
   "source": [
    "Recon3DModel_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hot net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pypi.org/project/decorator/3.3.2/ \n",
    "# install decorator"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('ml-air')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "894005d3a7f9e7f90f1d225b789862a942f5be96f0c7d0676c3b66e7cb3c009e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
